\documentclass{beamer}
%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]
  \setbeamertemplate{itemize items}[circle]
  \setbeamertemplate{theorems}[numbered]
  \setbeamercolor*{structure}{bg=white,fg=blue}
  \setbeamerfont{block title}{size=\normalsize}
}

% \newtheorem{proposition}[theorem]{Proposition}
% \theoremstyle{definition}
% \newtheorem{algorithm}[theorem]{Algorithm}
% \newtheorem{idea}[theorem]{Idea}

\usepackage[german]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{aligned-overset}
\usepackage{alltt}
\usepackage{amsmath}
\usepackage{csquotes}
% \usepackage{multicol}
% \usepackage{stmaryrd}
\usepackage{tabularx}

% \renewcommand\tabularxcolumn[1]{m{#1}}
% \newcolumntype{R}{>{\raggedleft\arraybackslash}X}=

\def\code#1{\texttt{\frenchspacing#1}}
\def\padding{\vspace{0.5cm}}
\def\spadding{\vspace{0.25cm}}
\def\b{\textcolor{blue}}
\def\r{\textcolor{red}}
\def\g#1{{\usebeamercolor[fg]{block title example}{#1}}}

% fix for \pause in align
\makeatletter
\let\save@measuring@true\measuring@true
\def\measuring@true{%
  \save@measuring@true
  \def\beamer@sortzero##1{\beamer@ifnextcharospec{\beamer@sortzeroread{##1}}{}}%
  \def\beamer@sortzeroread##1<##2>{}%
  \def\beamer@finalnospec{}%
}
\makeatother

\title[DWT Repetitorium]{Diskrete Wahrscheinlichkeitstheorie \\ Repetitorium}
\author{Jonas Hübotter}
\date{}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Outline}
 \tableofcontents[subsectionstyle=hide, subsubsectionstyle=hide]
\end{frame}
\AtBeginSection[]
  {
     \begin{frame}[allowframebreaks]{Plan}
     \tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
     \end{frame}
  }

\section{Zählen}

\subsection{Ergebnismengen und Ereignisse}
\begin{frame}{Ergebnismengen und Ereignisse}
    \begin{definition}
        Eine \b{Ergebnismenge} ist die Menge aller möglichen Elementarereignisse eines Experiments.
    \end{definition}\pause
    \begin{definition}
        Ein \b{Ereignis} ist eine Teilmenge der Ergebnismenge.
    \end{definition}\pause\padding
    Naive Definition der Wahrscheinlichkeit eines Ereignisses $A$ in der Ergebnismenge $S$:\pause
    \begin{align*}
        P(A) = \frac{\text{\# günstige Ergebnisse}}{\text{\# mögliche Ergebnisse}} = \frac{|A|}{|S|}
    \end{align*}\pause
    Annahmen:\pause
    \begin{itemize}
        \item alle Ergebnisse gleich wahrscheinlich\pause
        \item endlicher Ergebnisraum
    \end{itemize}
\end{frame}

\subsection{Abzählen von Mengen}
\begin{frame}{Abzählen von Mengen}
    \begin{block}{Multiplikationsregel}
        Betrachte $i \in [m]$ Experimente mit $n_i$ möglichen Ergebnissen. Dann ist die Gesamtanzahl an möglichen Ergebnissen
        \begin{align*}
            \prod_{i=1}^m n_i.
        \end{align*}
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Kombinatorik-Tabelle}
        Gegeben $n$ Objekte, wähle $k$ Objekte.
        \begin{block}{}\begin{tabularx}{\textwidth}{X||X|X}
            & Reihenfolge & $\neg$ Reihenfolge \\ \hline\hline
            \onslide<1->{Zurücklegen} & \onslide<2->{$n^k$} & \onslide<5->{$n + k - 1 \choose k$}\\
            \onslide<1->{$\neg$ Zurücklegen} & \onslide<4->{$\frac{n!}{(n - k)!}$} & \onslide<3->{$n \choose k$}
        \end{tabularx}\end{block}
    \end{block}
\end{frame}

\section{Wahrscheinlichkeit}
\subsection{$\sigma$-Algebren}
\begin{frame}{$\sigma$-Algebren}
    \begin{definition}
        Gegeben die Ergebnismenge $S$. Die Menge $\mathcal{A} \subseteq \mathcal{P}(S)$ ist eine \b{$\sigma$-Algebra} über $S$ wenn die folgenden Eigenschaften erfüllt sind:
        \begin{itemize}\pause
            \item $S \in \mathcal{A}$\pause;
            \item falls $A \in \mathcal{A}$, dann $\bar{A} \in \mathcal{A}$\pause; und
            \item $\forall n \in \mathbb{N}.\ A_n \in \mathcal{A} \implies \bigcup_{n=1}^{\infty} A_n \in \mathcal{A}$.
        \end{itemize}
    \end{definition}\pause\padding
    \r{Warum benötigen wir $\sigma$-Algebren?}\pause\par
    Um Ereignisse im Kontext eines Wahrscheinlichkeitsraumes beschreiben zu können.
\end{frame}

\subsection{Wahrscheinlichkeitsräume}
\begin{frame}{Wahrscheinlichkeitsräume}
    \begin{definition}
        Gegeben die Ergebnismenge $S$ und die $\sigma$-Algebra $\mathcal{A}$ über $S$.\pause\ Die Funktion
        \begin{align*}
            P: \mathcal{A} \to [0,1]
        \end{align*}
        ist ein \b{Wahrscheinlichkeitsmaß} auf $\mathcal{A}$ falls die \b{Kolmogorov Axiome} erfüllt sind:
        \begin{itemize}\pause
            \item $P(S) = 1$;\pause
            \item $P(\bigcup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} P(A_i)$ falls $\forall i \neq j.\ A_i \cap A_j = \emptyset$.
        \end{itemize}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Für ein Ereignis $A \in \mathcal{A}$, $P(A)$ ist die \b{Wahrscheinlichkeit} von $A$.
    \end{definition}\pause
    \begin{definition}
        Ein \b{Wahrscheinlichkeitsraum} besteht aus
        \begin{itemize}
            \item einer Ergebnismenge $S$;
            \item einer $\sigma$-Algebra $\mathcal{A}$ über $S$; und
            \item einem Wahrscheinlichkeitsmaß $P$ auf $\mathcal{A}$.
        \end{itemize}
    \end{definition}
\end{frame}

\begin{frame}
    Für einen Wahrscheinlichkeitsraum gelten die folgenden Eigenschaften:\pause
    \begin{itemize}
        \item $P(\emptyset) = 0$\pause
        \item $P(S) = 1$\pause
        \item $0 \leq P(A) \leq 1$ für alle $A \in \mathcal{A}$\pause
        \item $P(\bar{A}) = 1 - P(A)$ für alle $A \in \mathcal{A}$\pause
        \item falls $A, B \in \mathcal{A}$ und $A \subseteq B$, dann $P(A) \leq P(B)$
    \end{itemize}
\end{frame}

\begin{frame}
    Weiterhin gilt die \b{Siebformel}:
    \begin{align*}
        P(\bigcup_{i=1}^n A_i) = \sum_{I \in [n], I \neq \emptyset} (-1)^{|I| + 1} \cdot P(\bigcap_{i \in I} A_i).
    \end{align*}\pause\par\padding
    Und die \b{Bool'sche Ungleichung}:
    \begin{align*}
        P(\bigcup_{i=1}^n A_i) \leq \sum_{i=1}^n P(A_i).
    \end{align*}
\end{frame}

\subsection{Multivariate- und Randwahrscheinlichkeiten}
\begin{frame}{Multivariate- und Randwahrscheinlichkeiten}
    Eine \b{Randwahrscheinlichkeit} ist die Wahrscheinlichkeit eines einzelnen Ereignisses unabhängig von anderen Ereignissen.\pause\par\spadding
    Eine \b{multivariate Wahrscheinlichkeit} ist die Wahrscheinlichkeit von zwei oder mehreren Ereignissen gleichzeitig aufzutreten:
    \begin{align*}
        P(A,B) = P(A \cap B).
    \end{align*}
\end{frame}

\section{Bedingte Wahrscheinlichkeit}
\subsection{A-priori und a-posteriori}
\begin{frame}{A-priori und a-posteriori}
    Bedingte Wahrscheinlichkeit \textit{aktualisiert} die Wahrscheinlichkeit eines Ereignisses $A$ gegeben eine neue Information $B$.\pause\par\padding
    $P(A)$ heißt \b{a-priori} und $P(A|B)$ \b{a-posteriori} Wahrscheinlichkeit.\pause\par\padding
    \begin{align*}
        P(A|B) = \frac{P(A,B)}{P(B)}.
    \end{align*}
    Die a-posteriori Wahrschenilichkeit ist die multivariate Wahrscheinlichkeit des Ereignisses $A$ und der Information $B$ relativ zu der Wahrscheinlichkeit der Information $B$.
\end{frame}

\subsection{Unabhängigkeit}
\begin{frame}{Unabhängigkeit}
    Zwei Ereignisse sind \b{unabhängig} wenn das Auftreten des einen Ereignisses nicht die Wahrscheinlichkeit des anderen Ereignisses beeinflusst.\pause\par\padding
    Zwei Ereignisse $A$ und $B$ sind unabhängig\par
    $\iff P(A|B) = P(A)$\pause\par
    $\iff P(B|A) = P(B)$\pause\par
    $\iff P(A,B) = P(A) P(B)$.
\end{frame}

\subsection{Konditionierung}
\begin{frame}{Konditionierung}
    Einige Eigenschaften folgen direkt aus der Definition der bedingten Wahrscheinlichkeit:\pause
    \begin{itemize}
        \item $P(A,B) = P(B) P(A|B)\pause = P(A) P(B|A)$,\par da $A \cap B = B \cap A$\pause
        \item $P(A_1, \dots, A_n) = P(A_1) P(A_2|A_1) P(A_3|A_1, A_2) \cdots P(A_n|A_1, \dots, A_{n-1})$ (\b{Multiplikationssatz})\pause
        \item $P(A|B) = \frac{P(B|A) P(A)}{P(B)}$ (\b{Satz von Bayes})\pause
        \item $P(A) = P(A,B) + P(A,\bar{B}) = P(A|B) P(B) + P(A|\bar{B}) P(\bar{B})$ (\b{Gesetz der totalen Wahrscheinlichkeit})
    \end{itemize}
\end{frame}

\section{Diskrete Zufallsvariablen}
\begin{frame}{Diskrete Zufallsvariablen}
    \begin{definition}
        Eine \b{Zufallsvariable} $X$ ist eine Funktion
        \begin{align*}
            X: S \to \mathbb{R}.
        \end{align*}\pause
        Eine Zufallsvariable heißt \b{diskret} wenn ihr Urbild $S$ endlich oder abzählbar unendlich ist.
    \end{definition}\pause\padding
    Der Wertebereich einer diskreten Zufallsvariable
    \begin{align*}
        X(S) = \{x \in \mathbb{R}.\ \exists A \in S.\ X(A) = x\}
    \end{align*}
    ist ebenfalls abzählbar.
\end{frame}

\subsection{Verteilungsfunktion}
\begin{frame}{Verteilungsfunktion}
    $X \leq x$ ist ein Ereignis.\pause\par\padding
    \begin{definition}
        Die \b{Verteilungsfunktion} einer Zufallsvariable $X$ ist definiert als $F_X(x) = P(X \leq x) \in [0,1]$.
    \end{definition}\pause\par\spadding
    Eigenschaften von Verteilungsfunktionen:\pause
    \begin{itemize}
        \item monoton wachsend\pause
        \item rechtsseitig stetig\pause
        \item $F_X(x) \xrightarrow{x \to - \infty} 0$\pause
        \item $F_X(x) \xrightarrow{x \to \infty} 1$
    \end{itemize}\pause\padding
    Daher, $P(a < X \leq b) = F_X(b) - F_X(a)$.
\end{frame}

\subsection{Diskrete Dichtefunktion}
\begin{frame}{Diskrete Dichtefunktion}
    \begin{definition}
        Die \b{diskrete Dichtefunktion} einer diskreten Zufallsvariable $X$ ist definiert als $f_X(x) = P(X = x) \in [0,1]$ wobei
        \begin{align*}
            \sum_{x \in X(S)} f_X(x) = 1.
        \end{align*}
    \end{definition}
\end{frame}

\begin{frame}
    Die Verteilungsfunktion von $X$ kann von der Dichtefunktion von $X$ erhalten werden indem über die Dichtefunktion summiert wird
    \begin{align*}
        F_X(x) = \sum_{x' \leq x} f_X(x').
    \end{align*}\pause
    Die Dichtefunktion von $X$ kann von der Verteilungsfunktion von $X$ erhalten werden indem die \textit{Sprünge} in der Verteilungsfunktion identifiziert werden
    \begin{align*}
        f_X(x) = F_X(x) - F_X(prev(x)).
    \end{align*}
\end{frame}

\subsection{Unabhängigkeit}
\begin{frame}{Unabhängigkeit}
    Zwei Zufallsvariablen sind \b{unabhängig} wenn das Wissen des Wertes einer Zufallsvariable keine Auswirkungen auf die Verteilung der anderen Zufallsvariable hat.\pause\par\padding
    Zwei diskrete Zufallsvariablen $X$ und $Y$ sind unabhängig\par
    $\iff$ die Ereignisse $X=x$ und $Y=y$ sind unabhängig\pause\par
    $\iff$ die Ereignisse $X \leq x$ und $Y \leq y$ sind unabhängig.
\end{frame}

\subsection{Bernoulli Verteilung}
\begin{frame}{Bernoulli Verteilung}
    \begin{definition}[$X \sim Bern(p)$]
        Eine diskrete Zufallsvariable $X$ ist \b{Bernoulli}-verteilt mit Parameter $p$ falls $X(S) = \{0,1\}$ und $P(X=1) = p$.
    \end{definition}\pause
    \begin{exampleblock}{Übersicht}
        \begin{itemize}
            \item $E(X) = p$
            \item $Var(X) = p (1 - p)$
            \item $G_X(s) = 1 - p + p s$
            \item $M_X(s) = 1 - p + p e^s$
        \end{itemize}
    \end{exampleblock}
\end{frame}

\subsection{Erwartungswert}
\begin{frame}{Erwartungswert}
    \begin{definition}
        Der \b{Erwartungswert} $E(X)$ einer Zufallsvariable $X$ ist das arithmetische Mittel einer großen Anzahl an Realisierungen von $X$.\pause
        \begin{align*}
            E(X) &= \sum_{x \in X(S)} x \cdot P(X = x)\pause \\
                 &= \sum_{A \in S} X(A) \cdot P(A).
        \end{align*}
    \end{definition}\pause\par\padding
    Für unendlich große Wahrscheinlichkeitsräume ist \r{absolute Konvergenz} von $E(X)$ eine notwendige Bedingung für die Existenz von $E(X)$.
\end{frame}

\begin{frame}
    Eigenschaften des Erwartungswerts:\pause
    \begin{itemize}
        \item falls $\forall A \in S.\ X(A) \leq Y(A)$, dann $E(X) \leq E(Y)$ (\b{Monotonie})\pause
        \item $E(a \cdot X + b) = a \cdot E(X) + b$, $E(X + Y) = E(X) + E(Y)$ (\b{Linearität})\pause
        \item $E(\prod_{i=1}^n X_i) = \prod_{i=1}^n E(X_i)$ falls $X_1, \dots, X_n$ unabhängig (\b{Multiplikativität}).
    \end{itemize}
\end{frame}

\begin{frame}
    \begin{definition}
        $E(X^i)$ heißt \b{$i$-tes Moment} der Zufallsvariable $X$ und $E((X - E(X))^i)$ heißt \b{$i$-tes zetrales Moment} von $X$.
    \end{definition}
\end{frame}

\begin{frame}
    Das sogenannte \b{law of the unconscious statistician (LOTUS)} kann verwendet werden, um den Erwartungswert von transformierten Zufallsvariablen zu finden.
    \begin{align*}
        E(g(X)) = \sum_{x \in X(S)} g(x) \cdot P(X = x).
    \end{align*}
\end{frame}

\subsection{Indikatorvariablen}
\begin{frame}{Indikatorvariablen}
    \begin{definition}
        Gegeben ein Ereignis $A$, die Zufallsvariable $I_A \sim Bern(P(A))$ ist die \b{Indikatorvariable} des Ereignisses $A$.
    \end{definition}\pause\par\padding
    Eigenschaften von Indikatorvariablen:\pause
    \begin{itemize}
        \item $E(I_A) = P(A)$\pause
        \item $E(I_{A_1} \cdots I_{A_n}) = P(A_1 \cap \cdots \cap A_n)$.
    \end{itemize}
\end{frame}

\subsection{Binomialverteilung}
\begin{frame}{Binomialverteilung}
    \begin{definition}[$X \sim Bin(n,p)$]
        Eine diskrete Zufallsvariable $X$ ist \b{binomial}-verteilt mit Parametern $n$ und $p$ falls $X$ die \#Erfolge in $n$ unabhängigen $Bern(p)$ Versuchen modelliert.
    \end{definition}\pause
    \begin{align*}
        f_X(k) = {n \choose k} p^k (1 - p)^{n-k}.
    \end{align*}\pause
    \begin{exampleblock}{Übersicht}
        \begin{itemize}
            \item $E(X) = n p$\pause
            \item $Var(X) = n p (1 - p)$
            \item $G_X(s) = (1 - p + p s)^n$
            \item $M_X(s) = (1 - p + p e^s)^n$
        \end{itemize}
    \end{exampleblock}
\end{frame}

\subsection{Varianz}
\begin{frame}{Varianz}
    \begin{definition}
        Die \b{Varianz} $Var(X)$ einer Zufallsvariable $X$ ist ein Maß der absoluten Abweichung einer Zufallsvariablen von ihrem Erwartungswert.
        \begin{align*}
            Var(X) &= E((X - E(X))^2)\pause \\
                   &= E(X^2) - E(X)^2.
        \end{align*}\pause
        $SD(X) = \sqrt{Var(X)}$ heißt \b{Standardabweichung} von $X$.
    \end{definition}\pause\par\padding
    Eigenschaften der Varianz:\pause
    \begin{itemize}
        \item $Var(a \cdot X + b) = a^2 \cdot Var(X)$\pause
        \item $Var(\sum_{i=1}^n X_i) = \sum_{i=1}^n Var(X_i)$ falls $X_1, \dots, X_n$ unabhängig.
    \end{itemize}
\end{frame}

\subsection{Geometrische Verteilung}
\begin{frame}{Geometrische Verteilung}
    \begin{definition}[$X \sim Geom(p)$]
        Eine diskrete Zufallsvariable $X$ ist \b{geometrisch} verteilt mit Parameter $p$ falls $X$ die \#Versuche, die zu einem Erfolg führen, in unabhängigen $Bern(p)$ Versuchen modelliert.
    \end{definition}\pause
    \begin{columns}
        \begin{column}{0.5\textwidth}
           \begin{align*}
                f_X(k) = p (1 - p)^{k - 1}, k \in \mathbb{N}.
            \end{align*}
        \end{column}\pause
        \begin{column}{0.5\textwidth}
            \begin{align*}
                F_X(k) = 1 - (1 - p)^{\lfloor k \rfloor}.
            \end{align*}
        \end{column}
    \end{columns}\pause\par\padding
    \begin{exampleblock}{Übersicht}
        \begin{itemize}
            \item $E(X) = \frac{1}{p}$\pause
            \item $Var(X) = \frac{1 - p}{p^2}$\pause
            \item $G_X(s) = \frac{p s}{1 - (1 - p) s}$
            % \item $M_X(s) = \frac{p e^s}{1 - (1 - p) e^s}$ if $s < - ln(1 - p)$
        \end{itemize}
    \end{exampleblock}
\end{frame}

\begin{frame}
    \begin{block}{Gedächtnislosigkeit}
        Durchführen von $x$ Versuchen, von denen keiner zum Erfolg führt, verändert nicht die Wahrscheinlichkeit dafür, dass die nächsten $y$ Versuche einen Erfolg beinhalten.\pause\par\padding
        Diese Eigenschaft kann wie folgt formalisiert werden:
        \begin{align*}
            P(X > y + x | X > x) = P(X > y).
        \end{align*}\pause\par\padding
        Die geometrische Verteilung ist die \r{einzige} gedächtnislose diskrete Verteilung.
    \end{block}
\end{frame}

\subsection{Poisson Verteilung}
\begin{frame}{Poisson Verteilung}
    \begin{definition}[$X \sim Po(\lambda)$]
        Eine diskrete Zufallsvariable $X$ ist \b{Poisson}-verteilt mit Parameter $\lambda$ falls $X$ die \#Ereignisse in einem festen Interval mit Rate $\lambda$ modelliert, wobei die Ereignisse unabhängig von der Zeit seit dem letzten Ereignis auftreten.
    \end{definition}\pause
    \begin{columns}
        \begin{column}{0.5\textwidth}
           \begin{align*}
                f_X(k) = \frac{e^{- \lambda} \cdot \lambda^k}{k!}, k \in \mathbb{N}_0.
            \end{align*}
        \end{column}\pause
        \begin{column}{0.5\textwidth}
            \begin{align*}
                F_X(k) = e^{- \lambda} \cdot \sum_{i=0}^{\lfloor k \rfloor} \frac{\lambda^i}{i!}.
            \end{align*}
        \end{column}
    \end{columns}\pause\par\padding
    \begin{exampleblock}{Übersicht}
        \begin{itemize}
            \item $E(X) = \lambda$\pause
            \item $Var(X) = \lambda$\pause
            \item $G_X(s) = exp(\lambda (s - 1))$
            \item $M_X(s) = exp(\lambda (e^s - 1))$
        \end{itemize}
    \end{exampleblock}
\end{frame}

\begin{frame}
    \begin{block}{Poisson-Approximation der Binomialverteilung}
        Sei $X \sim Bin(n, \lambda / n)$.\pause\par
        Dann konvergiert die Verteilung von $X$ zu $Po(\lambda)$ mit $n \to \infty$\pause\par
        (d.h. für kleine $\lambda / n$).
    \end{block}
\end{frame}

\subsection{Wahrscheinlichkeitserzeugende Funktionen}
\begin{frame}{Wahrscheinlichkeitserzeugende Funktionen}
    \begin{definition}
        Gegeben eine diskrete Zufallsvariable $X$ mit $X(S) \subseteq \mathbb{N}_0$ ist die \b{wahrscheinlichkeitserzeugende Funktion} definiert als
        \begin{align*}
            G_X(s) &= \sum_{x \in X(S)} s^x \cdot P(X=x)\pause \\
                   &= E(s^X).
        \end{align*}
    \end{definition}\pause\par\padding
    Die wahrscheinlichkeitserzeugende Funktion einer Zufallsvariable $X$ erzeugt die Dichtefunktion von $X$:
    \begin{align*}
        P(X = i) = \frac{G_X^{(i)}(0)}{i!}.
    \end{align*}
\end{frame}

\begin{frame}
    Eigenschaften von wahrscheinlichkeitserzeugenden Funktionen:\pause
    \begin{itemize}
        \item $E(X) = G_X'(1)$\pause
        \item $Var(X) = G_X''(1) + G_X'(1) - (G_X'(1))^2$\pause
        \item $G_{X + t}(s) = s^t \cdot G_X(s), t \in \mathbb{N}_0$\pause
        \item $G_{X + Y}(s) = G_X(s) \cdot G_Y(s)$ falls $X,Y$ unabhängig.
    \end{itemize}
\end{frame}

\subsection{Momenterzeugende Funktionen}
\begin{frame}{Momenterzeugende Funktionen}
    \begin{definition}
       Gegeben eine Zufallsvariable $X$ ist die \b{momenterzeugende Funktion} definiert als
        \begin{align*}
            M_X(s) &= \sum_{x \in X(S)} e^{s x} \cdot P(X=x)\pause \\
                   &= E(e^{s X})\pause \\
                   &= \sum_{i=0}^{\infty} \frac{E(X^i)}{i!} \cdot s^i.
        \end{align*}
    \end{definition}\pause\par\padding
    Die momenterzeugende Funktion einer Zufallsvariable $X$ erzeugt das $i$-te Moment von $X$:
    \begin{align*}
        E(X^i) = M_X^{(i)}(0).
    \end{align*}
\end{frame}

\begin{frame}
    Eigenschaften von momenterzeugenden Funktionen:\pause
    \begin{itemize}
        \item $M_X(s) = G_X(e^s)$ if $X(S) \subseteq \mathbb{N}_0$ \pause
        \item $M_{X + Y}(s) = M_X(s) \cdot M_Y(s)$ falls $X,Y$ unabhängig.
    \end{itemize}
\end{frame}

\subsection{Multivariate Dichten}
\begin{frame}{Multivariate Dichten}
    \begin{definition}
        Eine \b{multivariate Dichte} ist die Dichte von zwei oder mehr Zufallsvariablen.
        \begin{align*}
            f_{X,Y}(x,y) = P(X = x, Y = y).
        \end{align*}\pause\par\spadding
        Die \b{Randdichte} einer Zufallsvariablen kann aus einer multivariaten Dichte gewonnen werden indem über alle anderen Zufallsvariablen summiert wird:
        \begin{align*}
            f_X(x) = \sum_{y \in Y(S)} f_{X,Y}(x,y).
        \end{align*}
    \end{definition}
\end{frame}

\subsection{Bedingte Dichten}
\begin{frame}{Bedingte Dichten}
    \begin{definition}
        Gegeben eine multivariate Dichte von zwei Zufallsvariablen $X$ und $Y$ ist die \b{bedingte Dichte} von $X$ gegeben $Y$ die Dichte von $X$ wenn der konkrete Wert von $Y$ bekannt ist.
        \begin{align*}
            f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)} = \frac{f_{Y|X}(y|x) \cdot f_X(x)}{f_Y(y)}.
        \end{align*}\pause\par\spadding
        Der \b{bedingte Erwartungswert} der Zufallsvariablen $X|Y=y$ ist der Erwartungswert der Dichte $f_{X|Y=y}$:
        \begin{align*}
            E(X|Y=y) = \sum_{x \in X(S)} x \cdot f_{X|Y}(x|y).
        \end{align*}
    \end{definition}
\end{frame}

\subsection{Faltungen}
\begin{frame}{Faltungen}
    \begin{definition}
        Seien die Zufallsvariablen $X$ und $Y$ unabhängig und $Z = X + Y$. Dann gilt
        \begin{align*}
            f_Z(z) = \sum_{x \in X(S)} f_X(x) \cdot f_Y(z - x).
        \end{align*}\pause
        Die Herleitung der Verteilung einer Summe von Zufallsvariablen gegeben deren Randverteilungen bezeichnet man auch als \b{Faltung} oder \b{Konvolution}.
    \end{definition}
\end{frame}

\subsection{Weitere Verteilungen}
\begin{frame}{Weitere Verteilungen}
    \begin{definition}[$X \sim HypGeom(r,a,b)$]
        Eine diskrete Zufallsvariable $X$ ist \b{hypergeometrisch} verteilt mit Parametern $r, a$ und $b$ falls $X$ die \# von gezogenen Objekten, die eine spezifische Eigenschaft haben, in $r$ Ziehungen ohne Zurücklegen aus $a + b$ Objekten modelliert webei $b$ Objekte die Eigenschaft aufweisen.\pause
        \begin{align*}
            f_X(x) = \frac{{b \choose x}{a \choose r - x}}{{a + b \choose r}}.
        \end{align*}\pause
        \begin{exampleblock}{Übersicht}
            \begin{itemize}
                \item $E(X) = r \cdot \frac{b}{a + b}$
            \end{itemize}
        \end{exampleblock}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}[$Z \sim NegBin(n,p)$]
        Eine diskrete Zufallsvariable $Z$ ist \b{negativ binomialverteilt} mit Parametern $n$ und $p$ falls $Z$ die \# von unabhängigen $Bern(p)$ Versuchen bevor dem $n$-ten Erfolg modelliert.\pause
        \begin{align*}
            f_Z(z) = {z - 1 \choose n - 1} p^n (1 - p)^{z - n}.
        \end{align*}\pause
        \begin{example}
            Seien $X_1, \dots, X_n \sim Geom(p)$ unabhängig und gleichverteilt.\par
            Dann gilt $Z = X_1 + \cdots + X_n \sim NegBin(n,p)$.
        \end{example}
    \end{definition}
\end{frame}

\subsection{Ungleichungen}
\begin{frame}{Ungleichungen}
    \begin{block}{Ungleichungen vs Approximationen}
        \textit{Approximationen} erlauben uns komplexere Probleme zu modellieren, doch ist oft nicht klar wie genau die Approximation ist.\par\pause
        \textit{Ungleichungen} erlauben uns definitive Aussagen (Schranken) bezüglich der Wahrscheinlichkeit von Ereignissen zu treffen.
    \end{block}
\end{frame}

\begin{frame}
    \begin{definition}[Markov]
        Gegeben eine Zufallsvariable $X \geq 0$ und $t > 0$
        \begin{align*}
            P(X \geq t) \leq \frac{E(X)}{t}.
        \end{align*}
    \end{definition}\pause
    \begin{definition}[Chebyshev]
        Gegeben eine Zufallsvariable $X$ und $t > 0$
        \begin{align*}
            P(|X - E(X)| \geq t) \leq \frac{Var(X)}{t^2}.
        \end{align*}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}[Chernoff]
        Seien $X_1, \dots, X_n$ unabhängige, Bernoulli-verteilte Zufallsvariablen mit $X_i \sim Bern(p_i)$. Dann gelten die folgenden Ungleichungen für $X = \sum_{i=1}^n X_i$ und $\mu = E(X) = \sum_{i=1}^n p_i$.\pause
        \begin{itemize}
            \item $P(X \geq (1 + \delta) \mu) \leq \left(\frac{e^{\delta}}{(1 + \delta)^{1 + \delta}}\right)^{\mu}$ für alle $\delta > 0$;
            \item $P(X \leq (1 - \delta) \mu) \leq \left(\frac{e^{- \delta}}{(1 - \delta)^{1 - \delta}}\right)^{\mu}$ für alle $0 < \delta < 1$\pause;
            \item $P(X \geq (1 + \delta) \mu) \leq e^{- \mu \delta^2 / 3}$ für alle $0 < \delta \leq 1$;
            \item $P(X \leq (1 - \delta) \mu) \leq e^{- \mu \delta^2 / 2}$ für alle $0 < \delta \leq 1$;
            \item $P(|X - \mu| \geq \delta \mu) \leq 2 e^{- \mu \delta^2 / 3}$ für alle $0 < \delta \leq 1$;
            \item $P(X \geq (1 + \delta) \mu) \leq \left(\frac{e}{1 + \delta}\right)^{(1 + \delta) \mu}$; and
            \item $P(X \geq t) \leq 2^{-t}$ für alle $t \geq 2 e \mu$.
        \end{itemize}
    \end{definition}
\end{frame}

\section{Kontinuierliche Zufallsvariablen}
\begin{frame}{Kontinuierliche Zufallsvariablen}
    \begin{definition}
        Eine \b{kontinuierliche Zufallsvariable} $X$ ist eine Funktion
        \begin{align*}
            X: S \to \mathbb{R}
        \end{align*}
        wobei $X(S)$ überabzählbar ist.\pause\par\spadding
        Die Verteilung von $X$ ist definiert durch die \b{kontinuierliche Dichtefunktion} $f_X: \mathbb{R} \to \mathbb{R}_0^+$ mit der Eigenschaft
        \begin{align*}
            \int_{- \infty}^{+ \infty} f_X(x)\ dx = 1.
        \end{align*}
    \end{definition}
\end{frame}

\subsection{Kontinuierliche Wahrscheinlichkeitsräume}
\begin{frame}{Kontinuierliche Wahrscheinlichkeitsräume}
    \begin{definition}
        Ein \b{Ereignis} ist eine Menge $A = \bigcup_k I_k \subseteq \mathbb{R}$, die durch eine Vereinigung abzählbar vieler paarweise disjunkter Intervalle repräsentiert werden kann. Die Wahrscheinlichkeit von $A$ ist gegeben als
        \begin{align*}
            P(A) = \int_A f_X(x)\ dx = \sum_k \int_{I_k} f_X(x)\ dx.
        \end{align*}
    \end{definition}\pause\par\padding
    \r{Die Wahrscheinlichkeit des Ereignisses $A = \{x\}, x \in \mathbb{R}$ ist immer $0$.}
\end{frame}

\begin{frame}
    \begin{block}{Verteilungsfunktion}
        Die Verteilungsfunktion einer kontinuierlichen Zufallsvariable $X$ ist gegeben als
        \begin{align*}
            F_X(x) &= P(X \leq x)\pause = P(X < x)\pause \\
                   &= \int_{- \infty}^x f_X(t)\ dt.
        \end{align*}\pause\par\spadding
        Die Dichtefunktion von $X$ kann durch die Verteilungsfunktion von $X$ erhalten werden indem ihre Ableitung bezüglich $x$ gefunden wird:
        \begin{align*}
            f_X(x) = \frac{dF_X}{dx}.
        \end{align*}
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Intervalle}
        Nach dem Hauptsatz der Differential- und Integralrechnung, ist die Wahrscheinlichkeit von $X \in [a,b]$ gegeben als
        \begin{align*}
            P(a \leq X \leq b) = F_X(b) - F_X(a) = \int_a^b f_X(x)\ dx.
        \end{align*}
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Erwartungswerte}
        Der Erwartungswert einer kontinuierlichen Zufallsvariable $X$ ist gegeben als
        \begin{align*}
            E(X) = \int_{- \infty}^{+ \infty} x \cdot f_X(x)\ dx.
        \end{align*}\pause\par\padding
        LOTUS gilt auch im kontinuierlichen Fall:
        \begin{align*}
            E(g(X)) = \int_{- \infty}^{+ \infty} g(x) \cdot f_X(x)\ dx.
        \end{align*}
    \end{block}
\end{frame}

\subsection{Gleichverteilung}
\begin{frame}{Gleichverteilung}
    \begin{definition}[$X \sim Unif(a,b)$]
        Eine kontinuierliche Zufallsvariable $X$ ist \b{gleichverteilt} mit Parametern $a$ und $b$ falls $X$ den Ausgang eines Experimentes modelliert, wo alle Ergebnisse, die in dem Intervall $[a,b]$ liegen, gleichwahrscheinlich sind.\pause
        \begin{columns}
            \begin{column}{0.5\textwidth}
               \begin{align*}
                    f_X(x) = \begin{cases}
                        \frac{1}{b - a} & \text{für $x \in [a,b]$} \\
                        0 & \text{sonst}
                    \end{cases}.
                \end{align*}
            \end{column}\pause
            \begin{column}{0.5\textwidth}
                \begin{align*}
                    F_X(x) = \begin{cases}
                        0 & \text{für $x < a$} \\
                        \frac{x - a}{b - a} & \text{für $x \in [a,b]$} \\
                        1 & \text{für $x > b$}
                    \end{cases}.
                \end{align*}
            \end{column}
        \end{columns}\pause\par\padding
        \begin{exampleblock}{Übersicht}
            \begin{itemize}
                \item $E(X) = \frac{a + b}{2}$\pause
                \item $Var(X) = \frac{(a - b)^2}{12}$
            \end{itemize}
        \end{exampleblock}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{block}{Universalität der Gleichverteilung}
        Sei $X \sim F$. Dann gilt $F(X) \sim Unif(0,1)$.\pause\par\spadding
        Realisierungen einer Zufallsvariablen mit Verteilung $F$ und inverser Verteilungsfunktion $F^{-1}$ können mittels Realisierungen einer gleichverteilten Zufallsvariablen $Y$ simuliert werden: $F^{-1}(Y) \sim F$.
    \end{block}
\end{frame}

\subsection{Normalverteilung}
\begin{frame}{Normalverteilung}
    \begin{definition}[$X \sim \mathcal{N}(\mu,\sigma^2)$]
        \begin{align*}
            f_X(x) = \frac{1}{\sigma \sqrt{2 \pi}} \cdot exp\left(-\frac{(x - \mu)^2}{2 \sigma^2}\right) =: \varphi(x;\mu,\sigma).
        \end{align*}
        \begin{align*}
            F_X(x) =: \Phi(x;\mu,\sigma).
        \end{align*}\pause
        \begin{exampleblock}{Übersicht}
            \begin{itemize}
                \item $E(X) = \mu$\pause
                \item $Var(X) = \sigma^2$\pause
                \item $M_Z(s) = exp(\mu s + \frac{(\sigma s)^2}{2})$
            \end{itemize}
        \end{exampleblock}
    \end{definition}
\end{frame}

\begin{frame}
    $\mathcal{N}(0,1)$ heißt \b{Standardnormalverteilung}.\pause\par\padding
    \begin{block}{Lineare Transformation}
        Sei $X \sim \mathcal{N}(\mu, \sigma^2)$. Dann ist für alle $a \in \mathbb{R} \setminus \{0\}$ und $b \in \mathbb{R}$ die Zufallsvariable
        \begin{align*}
            Y = a X + b
        \end{align*}
        normalverteilt mit Erwartungswert $a \mu + b$ und Varianz $a^2 \sigma^2$.
    \end{block}\pause\par\padding
    \begin{block}{Normierung}
        Sei $X \sim \mathcal{N}(\mu, \sigma^2)$ und $Y = \frac{X - \mu}{\sigma}$. Dann gilt $Y \sim \mathcal{N}(0,1)$.\pause\par
        Die Zufallsvariable $Y$ heißt auch \b{normiert}.
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Additivität}
        Seien $X_1, \dots, X_n$ unabhängig und normalverteilt mit Parametern $\mu_i, \sigma_i^2$. Dann ist die Zufallsvariable
        \begin{align*}
            Z = a_1 X_1 + \cdots + a_n X_n
        \end{align*}
        normalverteilt mit Erwartungswert $a_1 \mu_1 + \cdots a_n \mu_n$ und Varianz $a_1^2 \sigma_1^2 + \cdots + a_n^2 \sigma_n^2$.
    \end{block}\pause\par\padding
    \begin{block}{Normal-Approximation der Binomialverteilung}
        Sei $X \sim Bin(n,p)$ mit Verteilungsfunktion $F_n(t)$. Dann kann
        \begin{align*}
            F_n(t) \approx \Phi\left(\frac{t - n p}{\sqrt{p (1 - p) n}}\right)
        \end{align*}
        als Approximation verwendet werden falls $n p \geq 5$ und $n (1 - p) \geq 5$.
    \end{block}
\end{frame}

\subsection{$\gamma$-Quantil}
\begin{frame}{$\gamma$-Quantil}
    \begin{definition}
        Sei $X$ eine kontinuierliche Zufallsvariable mit Verteilung $F_x$. Eine Zahl $x_{\gamma}$ mit
        \begin{align*}
            F_X(x_{\gamma}) = \gamma
        \end{align*}
        heißt \b{$\gamma$-Quantil} von $X$ bzw. der Verteilung $F_X$.
    \end{definition}\pause\par\padding
    \begin{definition}
        Für die Standardnormalverteilung bezeichnet $z_{\gamma}$ das $\gamma$-Quantil.
    \end{definition}
\end{frame}

\subsection{Exponentialverteilung}
\begin{frame}{Exponentialverteilung}
    \begin{definition}[$X \sim Exp(\lambda)$]
        Eine kontinuierliche Zufallsvariable $X$ ist \b{exponentialverteilt} mit Parameter $\lambda$ falls $X$ die Zeit zwischen Ereignissen eines Poisson-Prozesses modelliert.\pause
        \begin{columns}
            \begin{column}{0.5\textwidth}
               \begin{align*}
                    f_X(x) = \lambda e^{- \lambda x}.
                \end{align*}
            \end{column}\pause
            \begin{column}{0.5\textwidth}
                \begin{align*}
                    F_X(x) = 1 - e^{- \lambda x}.
                \end{align*}
            \end{column}
        \end{columns}\pause\par\padding
        \begin{exampleblock}{Übersicht}
            \begin{itemize}
                \item $E(X) = \frac{1}{\lambda}$\pause
                \item $Var(X) = \frac{1}{\lambda^2}$\pause
                \item $M_X(s) = \frac{\lambda}{\lambda - s}, s < \lambda$
            \end{itemize}
        \end{exampleblock}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{block}{Skalierung}
        Sei $X \sim Exp(\lambda)$. Falls $a > 0$, dann ist $Y = a X$ exponentialverteilt mit dem Parameter $\lambda / a$.
    \end{block}\pause\par\padding
    \begin{block}{Gedächtnislosigkeit}
        Die Exponentialverteilung ist die \r{einzige} gedächtnislose kontinuierliche Verteilung. Daher ist jede kontinuierliche Zufallsvariable $X$ für die
        \begin{align*}
            P(X > y + x | X > x) = P(X > y)
        \end{align*}
        für all $x,y > 0$ gilt, exponentialverteilt.
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Warten auf mehrere Ereignisse}
        Seien $X_1, \dots, X_n$ unabhängige, exponentialverteilte Zufallsvariablen mit Parametern $\lambda_1, \dots, \lambda_n$. Dann ist $X = \min \{X_1, \dots, X_n\}$ exponentialverteilt mit Parameter $\lambda_1 + \cdots + \lambda_n$.
    \end{block}\pause\par\padding
    \begin{block}{Exponential-Approximation der geometrischen Verteilung}
        Sei $X_n \sim Geom(\lambda / n)$. Die Verteilung der skalierten geometrisch verteilten Zufallsvariablen $Y_n = \frac{1}{n} X_n$ konvergiert mit $n \to \infty$ zu einer Exponentialverteilung mit Parameter $\lambda$.
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Poisson-Prozess}
        Seien $T_1, T_2, \ldots \sim Exp(\lambda)$ unabhängige und gleichverteilte Zufallsvariablen, die die Zeit zwischen dem $(i - 1)$-ten und dem $i$-ten Ereignis modellieren.\pause\par
        Für $t > 0$ definieren wir
        \begin{align*}
            X(t) = \max \{n \in \mathbb{N} \mid T_1 + \cdots + T_n \leq t\},
        \end{align*}
        das die Anzahl der Ereignisse repräsentiert, die bis zum Zeitpunkt $t$ augetreten sind.\pause\par
        Dann ist $X(t)$ Poisson-verteilt mit Parameter $t \lambda$.
    \end{block}
\end{frame}

\subsection{Multivariate Verteilungen}
\begin{frame}{Multivariate Verteilungen}
    \begin{block}{Randverteilungen finden}
        Gegeben eine multivariate Verteilung $f_{X,Y}$ kann die Randverteilung $f_X$ wie folgt gefunden werden:
        \begin{align*}
            f_X(x) = \int_{- \infty}^{+ \infty} f_{X,Y}(x,y)\ dy.
        \end{align*}
    \end{block}\pause\par\padding
    \begin{block}{Wahrscheinlichkeiten berechnen}
        Gegeben ein Ereignis $A \in \mathbb{R}^2$. Die Wahrscheinlichkeit von $A$ ist die Fläche unter der Dichtefunktion von $X$:
        \begin{align*}
            P(A) = \iint\limits_{A} f_{X,Y}(x,y)\ dx\ dy.
        \end{align*}
    \end{block}
\end{frame}

\begin{frame}
    \begin{block}{Dichtefunktionen finden}
        Gegeben eine Verteilungsfunktion $F_{X,Y}$ kann die Dichtefunktion $f_{X,Y}$ wie folgt gefunden werden:
        \begin{align*}
            f_{X,Y}(x,y) = \frac{\partial^2 F_{X,Y}}{\partial x \partial y}(x,y).
        \end{align*}
    \end{block}\pause\par\padding
    \begin{block}{Verteilungsfunktionen finden}
        Gegeben eine Dichtefunktion $f_{X,Y}$ kann die Verteilungsfunktion $F_{X,Y}$ wie folgt gefunden werden:
        \begin{align*}
            F_{X,Y}(x,y) = \int_{- \infty}^y \int_{- \infty}^x f_{X,Y}(u,v)\ du\ dv.
        \end{align*}
    \end{block}
\end{frame}

\subsection{Weitere Verteilungen}
\begin{frame}{Weitere Verteilungen}
    \begin{definition}[$X \sim Lognormal(\mu, \sigma^2)$]
        Eine kontinuierliche Zufallsvariable $X$ ist \b{logarithmisch normalverteilt} mit Parametern $\mu$ und $\sigma^2$ falls $Y = ln(X) \sim \mathcal{N}(\mu, \sigma^2)$.\pause
        \begin{align*}
            f_X(x) = \frac{1}{x \sigma \sqrt{2 \pi}} \cdot exp\left(-\frac{(ln(x) - \mu)^2}{2 \sigma^2}\right).
        \end{align*}
    \end{definition}
\end{frame}

\section{Induktive Statistik}
\begin{frame}{Induktive Statistik}
    \b{Induktive Statistik} versucht mittels gemessener Größen auf zugrundeliegende Gesetzmäßigkeiten zu schließen.\pause\par
    Um Daten zu generieren, werden $n$ unabhängige Kopien eines identischen Experimentes durchgeführt, das durch die Zufallsvariable $X$ modelliert wird. Eine Messung, die aus einem dieser Experimente resultiert, heißt \b{Stichprobe}.\pause\par
    Jede Stichprobe wird durch eine separate Zufallsvariable $X_i$ repräsentiert, die als \b{Stichprobenvariable} bezeichnet wird.
\end{frame}

\subsection{Schätzer}
\begin{frame}{Schätzer}
    \begin{definition}
        Ein \b{Schätzer} für Parameter $\theta$ ist eine Zufallsvariable, die mehrere Stichprobenvariablen kombiniert und verwendet wird, um $\theta$ abzuschätzen.\pause\par\spadding
        Der \b{Bias} eines Schätzers $U$ ist gegeben als $E(U - \theta)$.\pause\par\spadding
        Ein Schätzer $U$ ist \b{erwartungstreu} bezüglich dem Parameter $\theta$ falls $E(U) = \theta$\par
        (d.h. der Bias des Schätzers ist Null).
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Das \b{Stichprobenmittel} $\bar{X}$ ist ein erwartungstreuer Schätzer für $E(X)$.
        \begin{align*}
            \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i.
        \end{align*}
    \end{definition}\pause\par\padding
    \begin{definition}
        Die \b{Stichprobenvarianz} $S^2$ ist ein erwartungstreuer Schätzer für $Var(X)$.
        \begin{align*}
            S = \sqrt{\frac{1}{n - 1} \sum_{i=1}^n (X_i - \bar{X})^2}.
        \end{align*}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Der \b{mean squared error} ist ein Gütemaß für einen Schätzer $U$.
        \begin{align*}
            MSE(U) = E((U - \theta)^2).
        \end{align*}\pause
        Falls $U$ erwartungstreu ist, so gilt $MSE(U) = Var(U)$.\pause\par\spadding
        Ein Schätzer $A$ ist \b{effizienter} als ein anderer Schätzer $B$ falls $MSE(A) < MSE(B)$.\par\pause\spadding
        Ein Schätzer $U$ ist \b{konsistent im quadratischen Mittel} falls $MSE(U) \xrightarrow{n \to \infty} 0.$
    \end{definition}
\end{frame}

\subsection{Maximum-Likelihood-Schätzer}
\begin{frame}{Maximum-Likelihood-Schätzer}
    Die \b{Maximum-Likelihood-Konstruktion} ist ein Verfahren zur Konstruktion eines Schätzers für Parameter von einer gegbenen Verteilung.\pause\par\padding
    Gegeben Stichproben $\overrightarrow{X} = (X_1, \dots, X_n)$ finde einen Maximum-Likelihood-Schätzer für $X$ mit Parameter $\theta$. $\overrightarrow{x} = (x_1, \dots, x_n)$ kombinieren alle Stichprobenwerte.
    \begin{enumerate}
        \item konstruiere $L(\overrightarrow{x}; \theta) = \prod_{i=1}^n f_X(x_i; \theta)$
        \item finde $\theta$, das $L$ maximiert
        \item der Wert für $\theta$, der $L$ maximiert, ist ein Maximum-Likelihood-Schätzer für $\theta$
    \end{enumerate}
\end{frame}

\subsection{Gesetz der großen Zahlen}
\begin{frame}{Gesetz der großen Zahlen}
    Das Gesetz der großen Zahlen besagt, dass das Stichprobenmittel aus unabhängigen und gleichverteilten Stichprobenvariablen $\bar{X}$ mit Wahrscheinlichkeit $1$ gegen den Erwartungswert $E(X)$ konvergiert während sich die Stichprobengröße $n$ Unendlich annähert.\pause
    \begin{align*}
        P(|\bar{X} - E(X)| \geq \delta) \leq \epsilon
    \end{align*}
    für $\delta, \epsilon > 0$ und $n \geq \frac{Var(X)}{\epsilon \delta^2}$.
\end{frame}

\subsection{Zentraler Grenzwertsatz}
\begin{frame}{Zentraler Grenzwertsatz}
    Der zentrale Grenzwertsatz besagt, dass die normierte Summe von Stichprobenvariablen sich einer Standardnormalverteilung annähert  während sich die Stichprobengröße $n$ Unendlich annähert selbst wenn die zugrundeliegende Verteilung nicht die Normalverteilung ist.\pause
    \begin{align*}
        \frac{\sum_{i=1}^n X_i - n \mu}{\sigma \sqrt{n}} \xrightarrow{n \to \infty} \mathcal{N}(0,1) \text{ in der Verteilung}
    \end{align*}
    für $X_i$ i.i.d..\pause\par\spadding
    Equivalent:
    \begin{align*}
        \sqrt{n} \left(\frac{\bar{X} - \mu}{\sigma}\right) \xrightarrow{n \to \infty} \mathcal{N}(0,1) \text{ in der Verteilung}.
    \end{align*}
\end{frame}

\begin{frame}
    \begin{block}{Grenzwertsatz nach de Moivre}
        Der Grenzwertsatz nach de Moivre ist ein Spezialfall des zentralen Grenzwertsatzes und sagt aus, dass die Normalverteilung als Approximation für die Binomialverteilung verwendet werden kann.\pause\par\spadding
        Seien $X_1, \dots, X_n \sim Bern(p)$ unabhängig und gleichverteilt sowie $H_n = X_1 + \cdots + X_n$. Dann gilt
        \begin{align*}
            H_n^* = \frac{H_n - n p}{\sqrt{n p (1 - p)}} \xrightarrow{n \to \infty} \mathcal{N}(0,1) \text{ in der Verteilung}.
        \end{align*}
    \end{block}
\end{frame}

\subsection{Konfidenzintervalle}
\begin{frame}{Konfidenzintervalle}
    Oft werden zwei Schätzer verwendet, um die abzuschätzende Größe aus beiden Richtungen abzuschätzen.\pause\par
    Die beiden Schätzer $U_1$ und $U_2$ werden so gewählt, dass
    \begin{align*}
        P(U_1 \leq \theta \leq U_2) \geq 1 - \alpha.
    \end{align*}\pause
    Die Wahrscheinlichkeit $1 - \alpha$ heißt \b{Konfidenzniveau}.\pause\par\padding
    Berechnen wir für konkrete Stichproben die Schätzer $U_1$ und $U_2$ und erwarten $\theta \in [U_1, U_2]$, dann liegt die Fehlerwahrscheinlichkeit bei $\alpha$. $[U_1, U_2]$ ist ein \b{Konfidenzintervall}.\pause\par\spadding
    Oft wird ein einziger Schätzer $U$ verwendet, um das symmetrische Konfidenzintervall $[U - \delta, U + \delta]$ zu definieren.
\end{frame}

\subsection{Hypothesentests}
\begin{frame}{Hypothesentests}
    Gegeben Stichprobenvariablen $\overrightarrow{X} = (X_1, \dots, X_n)$ und Stichprobenwerte $\overrightarrow{x} = (x_1, \dots, x_n)$ entscheide, ob eine Hypothese akzeptiert oder abgelehnt werden soll.\pause\par\padding
    $K = \{\overrightarrow{x} \in \mathbb{R}^n \mid \overrightarrow{x} \text{ resultiert in Ablehnung der Hypothese}\}$ heißt \b{kritischer Bereich} (oder \b{Ablehnungsbereich}) eines Tests.\pause\par\padding
    $K$ wird basierend auf den konkreten Werten der \b{Testvariablen} $T$ gewählt, die sich aus den Stichprobenvariablen zusammensetzt.\pause\par\padding
    Ein Test heißt \b{einseitig} falls $K$ ein halboffenes Intervall in $T(S)$ ist und \b{beidseitig} falls $K$ ein geschlossenes Intervall in $T(S)$ ist.
\end{frame}

\begin{frame}
    $H_0$ ist die Hypothese auf die getestet wird, auch als \b{Nullhypothese} bezeichnet.\par
    $H_1$ ist die \b{Alternative}. $H_1$ ist \b{trivial} falls es die einfache Negation von $H_0$ ist.\pause\par\padding
    \begin{block}{Fehler}
        \begin{itemize}
            \item \b{Fehler 1. Art} oder \b{$\alpha$-Fehler} oder \b{Signifikanzniveau}\par
                $H_0$ gilt, aber $\overrightarrow{x} \in K$
                \begin{align*}
                    \alpha = \sup_{p \in H_0} P_p(T \in K).
                \end{align*}\pause
            \item \b{Fehler 2. Art} oder \b{$\beta$-Fehler}\par
                $H_1$ gilt, aber $\overrightarrow{x} \not\in K$
                \begin{align*}
                    \beta = \sup_{p \in H_1} P_p(T \not\in K).
                \end{align*}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}
    Die \b{Gütefunktion} $g$ beschreibt die Wahrscheinlichkeit, dass ein Test die Nullhypothese ablehnt.
    \begin{align*}
        g(p) = P_p(T \in K).
    \end{align*}
\end{frame}

\subsection{Statistische Tests}
\begin{frame}{Statistische Tests}
    \begin{block}{Eigenschaften}
        Statistische Tests können anhand einiger Merkmale unterschieden werden:
        \begin{itemize}
            \item \textbf{Anzahl beteiligter Zufallsgrößen}\pause\par
                Vergleich zweier Zufallsvariablen mit potenziell unterschiedlichen Verteilungen (\b{Zwei-Stichproben-Test}), oder Untersuchung einer Zufallsvariable (\b{Ein-Stichproben-Test})?\pause
                \begin{itemize}
                    \item Unabhängigkeit beteiligter Zufallsvariablen\par
                        Bei dem Vergleich mehrerer Zufallsvariablen wird unterschieden, ob \b{unabhängige Messungen} (Unabhängigkeit) oder \b{verbundene Messungen} (Abhängigkeit) vorgenommen werden.\pause
                    \item Betrachtung des Zusammenhangs mehrerer Zufallsvariablen\par
                        Wird der funktionale Zusammenhang mehrerer Zufallsvariablen untersucht spricht man von einer \b{Regressionsanalyse}. Werden die Zufallsvariablen auf Unabhängigkeit untersucht spricht man von einer \b{Zusammenhangsanalyse}.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}
    \begin{itemize}
        \item \textbf{Formulierung der Nullhypothese}\pause\par
            Über welche \b{Lageparameter} macht der Test eine Aussage (z.B Erwartungswert oder Varianz), oder wird auf eine vorgegebene Verteilung getestet?\pause
        \item \textbf{Annahmen über die Zufallsgrößen}\pause\par
            Welche Annahmen macht der Test über die Zufallsvariablen wie zum Beispiel die Art der Verteilung, Erwartungswert, oder Varianz?
    \end{itemize}
\end{frame}

\begin{frame}
    \begin{block}{Wichtige statistische Testverfahren}\pause
        \begin{itemize}
            \item Approximativer Binomialtest\pause
            \item Gaußtest\pause
            \item $t$-Test\pause
            \item Zwei-Stichproben-$t$-Test\pause
            \item $\chi^2$-Anpassungstest
        \end{itemize}
    \end{block}
\end{frame}

\section{Markovketten}
\subsection{Stochastische Prozesse}
\begin{frame}{Stochastische Prozesse}
    \begin{definition}
        Ein \b{stochastischer Prozess} ist eine Folge von Zufallsvariablen $(X_t)_{t \in T}$, die das Verhalten eines Systems zu verschiedenen Zeitpunkten $t$ angeben.\pause\par\spadding
        Gilt $T = \mathbb{N}_0$, so spricht man von einem stochastischen Prozess mit \b{diskreter Zeit}.\pause\ Gilt hingegen $T = \mathbb{R}_0^+$, so spricht man von einem stochastischen Prozess mit \b{kontinuierlicher Zeit}.\par
        Falls $X_t$ diskret ist, spricht man auch von unterschiedlichen \b{Zuständen} die ein System zum Zeitpunkt $t$ annimmt.
    \end{definition}
\end{frame}

\subsection{Markov-Bedingung}
\begin{frame}{Markov-Bedingung}
    \begin{definition}
        Ein stochastischer Prozess erfüllt die \b{Markov-Bedingung}, falls die Wahrscheinlichkeitsverteilung der Zustände zum Zeitpunkt $t + 1$ nur von der Wahrscheinlichkeitsverteilung der Zustände zum Zeitpunkt $t$ abhängt, nicht aber von Zuständen zum Zeitpunkt $< t$.\pause\par\spadding
        Diese Bedingung kann wie folgt formalisiert werden:
        \begin{align*}
            P(X_{t+1} = j | X_t = i_t, \dots, X_0 = i_0) = P(X_{t+1} = j | X_t = i_t)\pause =: p_{i_t j}^t.
        \end{align*}
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Eine \b{(endliche) Markov-Kette} (mit diskreter Zeit) über Zustandsmenge $S = \{0, \dots, n-1\}$ besteht aus einer unendlichen Folge von Zufallsvariablen $(X_t)_{t \in \mathbb{N}_0}$ wit Wertebereich $S$\pause\ und \b{Startverteilung} $q_0$ mit $q_0^T \in \mathbb{R}^n$.\pause\ $q_0$ muss als Zeilenvektor eine valide diskrete Dichtefunktion auf der Zustandsmenge $S$ beschreiben.\pause\par
        Weiterhin muss die Markov-Bedingung erfüllt sein.
    \end{definition}
\end{frame}

\subsection{Repräsentationen}
\begin{frame}{Repräsentationen}
    \begin{definition}
        Sind die Übergangswahrscheinlichkeiten $p_{ij} = P(X_{t+1} = j | X_t = i)$ konstant mit der Zeit $t$, so spricht man von einer \b{(zeit-)homogenen} Markov-Kette.\par\pause\spadding
        In diesem Fall definiert man die \b{Übergangsmatrix} durch $P = (p_{ij})_{0 \leq i, j < n}$.\par\pause\spadding
        Das \b{Übergangsdiagramm} ist ein Graph bestehend aus den Zuständen $S$ wobei die gewichteten Kanten durch $P$ repräsentiert werden.
    \end{definition}\par\pause\padding
    Einen konkreten Ablauf des Systems kann man sich auch als Random Walk auf dem Übergangsdiagramm vorstellen.
\end{frame}

\subsection{Wahrscheinlichkeiten}
\begin{frame}{Wahrscheinlichkeiten}
    Die Verteilung einer Markov-Kette kann iterativ für immer größere Zeitpunkte $t$ bestimmt werden:
    \begin{align*}
        q_{t+1} &= q_t \cdot P\pause \\
        q_t     &= q_0 \cdot P^t\pause \\
        q_{t+k} &= q_t \cdot P^k.
    \end{align*}\pause
    \begin{definition}
        $q_t$ wird auch als \b{Zustandsvektor} der Markov-Kette zum Zeitpunkt $t$ bezeichnet.
    \end{definition}\par\pause\padding
    Die Einträge von $P^k$ geben an, mit welcher Wahrscheinlichkeit ein Übergang von Zustand $i$ in Zustand $j$ in genau $k$ Schritten erfolgt:
    \begin{align*}
        p_{ij}^{(k)} = P(X_{t+k} = j | X_t = i) = (P^k)_{ij}.
    \end{align*}
\end{frame}

\subsection{Übergangszeiten}
\begin{frame}{Übergangszeiten}
    \begin{definition}
        Die \b{Übergangszeit} von Zustand $i$ in Zustand $j$ wird durch die folgende Zufallsvariable modelliert:
        \begin{align*}
            T_{ij} = \min \{n \geq 1 \mid X_n = j, \text{ wenn } X_0 = i\}.
        \end{align*}\pause
        Die \b{erwartete Übergangszeit} ist gegeben durch
        \begin{align*}
            h_{ij} &= E(T_{ij})\pause \\
                   &= 1 + \sum_{k \neq j} p_{ik} h_{kj}.
        \end{align*}
    \end{definition}
\end{frame}

\begin{frame}
    Die Wahrscheinlichkeit vom Zustand $i$ in beliebig vielen Schritten in den Zustand $j$ zu gelangen, heißt \b{Ankunftswahrscheinlichkeit} $f_{ij}$:
    \begin{align*}
        f_{ij} &= P(T_{ij} < \infty)\pause \\
               &= p_{ij} + \sum_{k \neq j} p_{ik} f_{kj}.
    \end{align*}\pause
    \begin{definition}
        Die Zufallsvariable $T_i = T_{ii}$ gibt die \b{Rückkehrzeit} von Zustand $i$ zu Zustand $i$ an.\pause\par\spadding
        Die \b{erwartete Rückkehrzeit} $h_i = h_{ii}$ und die \b{Rückkehrwahrscheinlichkeit} $f_i = f_{ii}$ sind analog zu der erwarteten Übergangszeit und der Ankunftswahrscheinlichkeit definiert.
    \end{definition}
\end{frame}

\subsection{Stationäre Verteilung}
\begin{frame}{Stationäre Verteilung}
    \begin{definition}
        Ein Zustandsvektor $\pi$ mit $\pi = \pi \cdot P$ heißt \b{stationäre Verteilung} einer Markov-Kette.
    \end{definition}\par\pause\padding
    Eine Markovkette konvergiert nicht notwendigerweise in eine ihrer stationären Verteilungen. Konvergenz hängt von den Eigenschaften der Markovkette und der Startverteilung ab.
\end{frame}

\subsection{Exkurs: Diagonalisierung}
\begin{frame}{Exkurs: Diagonalisierung}
    Für Eigenvektoren $x_i$ und zugehörige Eigenwerte $\lambda_i$ einer Matrix $A$ gilt $A \cdot x_i = \lambda_i \cdot x_i$.\pause\par\spadding
    Damit gilt für eine quadratische Matrix $A$ mit Eigenvektoren $x_1, \dots, x_n$ und zugehörigen Eigenwerten $\lambda_1, \dots, \lambda_n$\pause, dass
    \begin{align*}
        A \cdot \begin{bmatrix}
            x_1 & \cdots & x_n
        \end{bmatrix}\pause &= \begin{bmatrix}
            \lambda_1 x_1 & \cdots & \lambda_n x_n
        \end{bmatrix}\pause \\
        &= \begin{bmatrix}
            x_1 & \cdots & x_n
        \end{bmatrix} \cdot \begin{bmatrix}
            \lambda_1 & 0 & 0 \\
            0 & \ddots & 0 \\
            0 & 0 & \lambda_n
        \end{bmatrix}.
    \end{align*}\pause
    Sei $V$ die Matrix bestehend aus den Eigenvektoren von $A$ als Spaltenvektoren und sei $\Lambda$ die Diagonalmatrix bestehend aus den Eigenwerten von $A$.\pause\par\spadding
    Dann heißt $V^{-1} \cdot A \cdot V = \Lambda$ \b{Diagonalisierung} von $A$.\pause\par
    Andererseits gilt auch, dass $A = V \cdot \Lambda \cdot V^{-1}$.
\end{frame}

\subsection{Konvergenz}
\begin{frame}{Konvergenz}
    Aus der Diagonalisierung der Übergangsmatrix folgt direkt, dass
    \begin{align*}
                                     P^t &= V \cdot \Lambda^t \cdot V^{-1}.
    \end{align*}\pause
    Damit kann das Verhalten der Markovkette für $t \to \infty$ beschreiben werden:
    \begin{align*}
        &\lim_{t \to \infty} q_t\pause = \lim_{t \to \infty} q_0 \cdot P^t.\pause \\
        &\lim_{t \to \infty} P(X_t = j \mid X_0 = i)\pause = \lim_{t \to \infty} P^t(i,j).
    \end{align*}
\end{frame}

\subsection{Eigenschaften}
\begin{frame}{Eigenschaften}
    Weißt eine Markovkette bestimmte Eigenschaften auf, können Rückschlüsse auf ihre stationäre Verteilung gezogen werden.\pause\par\padding
    \begin{definition}
        Ein Zustand $i$ heißt \b{absorbierend}, falls $p_{ii} = 1$, d.h. aus ihm führen keine Übergänge heraus.\pause\par\spadding
        Ein Zustand $i$ heißt \b{rekurrent}, falls $f_{i} = 1$, d.h. mit Wahrscheinlichkeit $1$ kehrt die Markovkette in den Zustand $i$ zurück.\pause\par
        Falls hingegen $f_{i} < 1$ gilt, heißt der Zustand $i$ \b{transient}.
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Eine Markov-Kette heißt \b{irreduzibel} wenn man von jedem Zustand jeden anderen Zustand mit positiver Wahrscheinlichkeit erreicht, wenn man nur genügend Schritte ausführt.\pause\ Das heißt formal:
        \begin{align*}
            \forall i, j \in S.\ \exists n \in \mathbb{N}.\ p_{ij}^{(n)} > 0.
        \end{align*}\pause
        Eine endliche Markov-Kette ist genau dann irreduzibel wenn ihr Übergangsdiagramm stark zusammenhängend ist.\pause\par\spadding
        Wenn eine endliche Markov-Kette irreduzibel ist   gilt zudem:\pause
        \begin{itemize}
            \item $f_{ij} = 1, \forall i, j \in S$\pause;
            \item $h_{ij} \text{ existiert}, \forall i, j \in S$\pause; und
            \item es existiert eine eindeutige stationäre Verteilung $\pi$ mit $\pi(j) = \frac{1}{h_{j}}, \forall j \in S$.
        \end{itemize}\pause
        \r{Die Markov-Kette muss nicht zwingend in eine stationäre Verteilung konvergieren (Periodizität!).}
    \end{definition}
\end{frame}

\begin{frame}
    Nun wollen wir die Periodizität von Zuständen betrachten.\pause
    \begin{definition}
        Für einen Zustand $i$ definieren wir
        \begin{align*}
            T(i) = \{n \geq 1 \mid P^n(i,i) > 0\}.
        \end{align*}\pause
        Dann ist die \b{Periode} des Zustandes $i$ definiert als $d_i = gcd(T(i))$.\pause\par\padding
        Falls eine Markovkette irreduzibel ist, ist die Periode aller Zustände gleich. Diese Periode wird dann als Periode der Markovkette bezeichnet.
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Ein Zustand $i$ heißt \b{aperiodisch}, falls $d_i = 1$\pause, oder equivalent, falls $
\exists n_0 \in \mathbb{N}.\ \forall n \geq n_0.\ p_{ii}^{(n)} > 0$.\pause\par\spadding
        Somit ist ein Zustand $i$ aperiodisch genau dann wenn es im Übergansdiagramm für alle $n \in \mathbb{N}$ ab einem $n_0 \in \mathbb{N}$ einen geschlossenen Weg der Länge $n$ von $i$ nach $i$ gibt.\pause\par\spadding
        Das heißt Zustand $i$ ist sicherlich dann aperiodisch wenn er im Übergangsdiagramm
        \begin{itemize}
            \item eine Schleife besitzt ($p_{ii} > 0$)\pause\ oder
            \item auf mindestens zwei geschlossenen Pfaden $P_1$ und $P_2$ liegt, deren Längen teilerfremd sind.
        \end{itemize}\pause\par\padding
        Eine Markov-Kette heißt \b{aperiodisch} falls alle ihre Zustände aperiodisch sind.
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        Eine irreduzible und aperiodische Markov-Kette heißt \b{ergodisch}.
    \end{definition}\pause\par\padding
    Für jede endliche ergodische Markov-Kette gilt unabhängig der Startverteilung $q_0$, dass
    \begin{align*}
        \lim_{t \to \infty} q_t = \pi
    \end{align*}
    wobei $\pi$ die eindeutige stationäre Verteilung bezeichnet.
\end{frame}

\begin{frame}
    \begin{definition}
        Eine quadratische Matrix $A$ heißt \b{stochastisch}, falls sich alle Zeilen zu Eins aufsummieren.\pause\par
        Jede Übergangsmatrix $P$ ist stochastisch.\pause\par\spadding
        $A$ heißt zusätzlich \b{doppeltstochastisch}, falls sich auch alle Spalten zu Eins aufsummieren.
    \end{definition}\pause\par\padding
    Für jede endliche ergodische Markov-Kette mit doppeltstochastischer Übergangsmatrix gilt, dass die stationäre Verteilung jedem Zustand die gleiche Wahrscheinlichkeit zuweist:
    \begin{align*}
        \pi \equiv \frac{1}{|S|}.
    \end{align*}
\end{frame}

\end{document}
